import json
import os
from kafka import KafkaConsumer
import psycopg2
from pymongo import MongoClient

# --- C·∫§U H√åNH ---
# B·∫°n n√™n s·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng trong th·ª±c t·∫ø
KAFKA_BROKER_URL = os.environ.get("KAFKA_BROKER_URL", "localhost:9092")

# C√°c topic c·∫ßn l·∫Øng nghe (thay b·∫±ng t√™n topic c·ªßa b·∫°n)
# V√≠ d·ª•: n·∫øu database.server.name trong config Debezium l√† "pg-server-1"
# v√† b·∫°n c√≥ c√°c b·∫£ng "orders", "order_items", "users"
TOPICS = ["dbserver1.public.orders"] 

POSTGRES_CONN_STRING = "host='localhost' dbname='dinhnt' user='postgres' password='dinhnt'"
MONGO_CONN_STRING = os.environ.get("MONGO_CONN_STRING", "mongodb://localhost:27017/")
MONGO_DB = "dinhnt"
MONGO_COLLECTION = "users"


# --- H√ÄM TRUY V·∫§N V√Ä TR·∫¢I PH·∫≤NG D·ªÆ LI·ªÜU ---

def get_full_order_details(order_id, pg_cursor):
    """
    Truy v·∫•n t·∫•t c·∫£ d·ªØ li·ªáu li√™n quan ƒë·∫øn m·ªôt order_id v√† tr·∫£i ph·∫≥ng n√≥.
    ƒê√¢y l√† logic c·ªët l√µi b·∫°n c·∫ßn t√πy ch·ªânh theo schema c·ªßa m√¨nh.
    """
    query = """
    SELECT
        o.order_id,
        o.order_date,
        o.status AS order_status,
        u.user_id,
        u.username,
        u.email,
        json_agg(
            json_build_object(
                'product_id', p.product_id,
                'product_name', p.product_name,
                'price', p.price,
                'quantity', oi.quantity
            )
        ) FILTER (WHERE p.product_id IS NOT NULL) AS items
    FROM orders o
    LEFT JOIN users u ON o.user_id = u.user_id
    LEFT JOIN order_items oi ON o.order_id = oi.order_id
    LEFT JOIN products p ON oi.product_id = p.product_id
    WHERE o.order_id = %s
    GROUP BY o.order_id, u.user_id;
    """
    try:
        pg_cursor.execute(query, (order_id,))
        result = pg_cursor.fetchone()

        print(f"Result {result}")

        if not result:
            return None

        # Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ t·ª´ tuple sang dictionary
        columns = [desc[0] for desc in pg_cursor.description]
        flat_document = dict(zip(columns, result))
        
        # ƒê·∫∑t _id cho MongoDB ƒë·ªÉ c√≥ th·ªÉ upsert, v√† ƒë·∫£m b·∫£o n√≥ duy nh·∫•t
        flat_document['_id'] = flat_document['order_id']
        
        return flat_document
    except Exception as e:
        print(f"Error fetching data for order_id {order_id}: {e}")
        return None


# --- V√íNG L·∫∂P CH√çNH C·ª¶A CONSUMER ---

def main():
    print("üöÄ Starting Sync Service...")
    
    # Thi·∫øt l·∫≠p k·∫øt n·ªëi
    try:
        pg_conn = psycopg2.connect(POSTGRES_CONN_STRING)
        mongo_client = MongoClient(MONGO_CONN_STRING)
        mongo_db = mongo_client[MONGO_DB]
        mongo_collection = mongo_db[MONGO_COLLECTION]
        print("‚úÖ Connected to PostgreSQL and MongoDB.")

        # cursor = pg_conn.cursor()
        # cursor.execute("SELECT * FROM users LIMIT 5;") 
        # rows = cursor.fetchall()
        # print("Data", rows)
        
    except Exception as e:
        print(f"üî• Could not connect to databases: {e}")
        return

    consumer = KafkaConsumer(
        *TOPICS,
        bootstrap_servers=KAFKA_BROKER_URL,
        # ƒê·ªçc message d∆∞·ªõi d·∫°ng JSON
        value_deserializer=lambda v: json.loads(v.decode('utf-8')),
        # B·∫Øt ƒë·∫ßu ƒë·ªçc t·ª´ ƒë·∫ßu n·∫øu l√† consumer m·ªõi
        auto_offset_reset='earliest',
        # T·ª± ƒë·ªông commit offset
        enable_auto_commit=True,
        group_id='mongodb-sync-group' # ƒê·∫∑t t√™n group cho consumer
    )
    print(f"üëÇ Listening to consumer check: {consumer}")
    print(f"üëÇ Listening to Kafka topics: {', '.join(TOPICS)}")
    
    pg_cursor = pg_conn.cursor()

    for message in consumer:
        print("Topic:", consumer.subscription)
        try:
            payload = message.value.get("payload")
            if not payload:
                continue

            # L·∫•y th√¥ng tin v·ªÅ thao t√°c (create, update, delete)
            op = payload.get("op") 
            # D·ªØ li·ªáu sau khi thay ƒë·ªïi (cho create/update)
            data = payload.get("after") if op != 'd' else payload.get("before")

            if not data:
                continue

            # X√°c ƒë·ªãnh ID ch√≠nh c·∫ßn ƒë∆∞·ª£c ƒë·ªìng b·ªô l·∫°i
            order_id = data.get("order_id")

            # N·∫øu s·ª± ki·ªán ƒë·∫øn t·ª´ b·∫£ng `users`, ch√∫ng ta c·∫ßn t√¨m t·∫•t c·∫£ c√°c order li√™n quan
            if message.topic.endswith("users"):
                # ƒê√¢y l√† ph·∫ßn x·ª≠ l√Ω n√¢ng cao, t·∫°m th·ªùi b·ªè qua ƒë·ªÉ ƒë∆°n gi·∫£n
                pass

            if not order_id:
                # print(f"‚ö†Ô∏è Message on topic {message.topic} doesn't have order_id. Skipping.")
                continue

            print(f"üì¨ Event (op: {op}) on topic '{message.topic}' for order_id: {order_id}. Rebuilding document...")

            if op == 'd' and message.topic.endswith("orders"):
                # N·∫øu to√†n b·ªô ƒë∆°n h√†ng b·ªã x√≥a
                mongo_collection.delete_one({'_id': order_id})
                print(f"üóëÔ∏è Deleted document for order_id: {order_id} from MongoDB.")
            else:
                # X√¢y d·ª±ng l·∫°i to√†n b·ªô document t·ª´ PostgreSQL
                full_document = get_full_order_details(order_id, pg_cursor)

                if full_document:
                    # Ghi ƒë√® (ho·∫∑c t·∫°o m·ªõi) v√†o MongoDB
                    mongo_collection.update_one(
                        {'_id': full_document['_id']},
                        {'$set': full_document},
                        upsert=True
                    )
                    print(f"‚úÖ Synced document for order_id: {order_id} to MongoDB.")

        except Exception as e:
            print(f"üî• An error occurred while processing message: {e}")
            # Trong m√¥i tr∆∞·ªùng production, b·∫°n c·∫ßn c√≥ c∆° ch·∫ø x·ª≠ l√Ω l·ªói t·ªët h∆°n
            # v√≠ d·ª• nh∆∞ g·ª≠i message l·ªói v√†o m·ªôt Dead-Letter Queue (DLQ).
    
    pg_cursor.close()
    pg_conn.close()

if __name__ == "__main__":
    main()